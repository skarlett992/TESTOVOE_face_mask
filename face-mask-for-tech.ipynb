{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Классификация лиц в масках/без с помощью передачи обучения из предварительно обученной сети EfficientNetB3"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pathlib\nimport os\n\n#Используем буферизованную предварительную выборку для загрузки изображений с диска без блокировки ввода-вывода\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndata_root_orig='/kaggle/input/face-mask-dataset/data'\n\nclass_names = ['with_mask', 'without_mask']\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\noutput_path='/kaggle/working/'","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(path, image_size):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [image_size[0], image_size[1]])\n    return image\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_img(train_dataset):\n    import matplotlib.pyplot as plt\n    data_augmentation = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    ])\n    for image, _ in train_dataset.take(1):\n        plt.figure(figsize=(10, 10))\n        first_image = image[0]\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n            plt.imshow(augmented_image[0] / 255)\n            plt.axis('off')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom(class_names, data_root_orig, batch, image_size):\n    data_root = pathlib.Path(data_root_orig)\n    all_image_paths = list(data_root.rglob('*/*.jpg'))\n    all_image_paths = [str(path) for path in all_image_paths if pathlib.Path(path).is_file()]\n\n    image_count = len(all_image_paths)\n\n    label_names = []\n    for path in all_image_paths:\n        if pathlib.Path(path).parent.name == class_names[0]:\n            label_names.append(0)\n        else:\n            label_names.append(1)\n\n    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n    image_ds = path_ds.map(lambda path: preprocess_image(path, image_size), num_parallel_calls=AUTOTUNE)\n    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(label_names, tf.int64))\n    image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n\n    # Установка размера буфера перемешивания, равного набору данных, гарантирует\n    # полное перемешивание данных.\n    ds = image_label_ds.shuffle(buffer_size=image_count)\n    ds = ds.repeat()\n    ds = ds.batch(batch)\n\n    size_ds = image_count\n    train_size = int(0.8*size_ds)\n    test_size = int(0.2*size_ds)\n    train_ds = ds.take(train_size)\n    test_ds = ds.skip(train_size)\n    test_ds = ds.take(test_size)\n\n    return train_ds, test_ds","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset, validation_dataset = custom(\n    class_names = class_names,\n    data_root_orig = data_root_orig,\n    batch = BATCH_SIZE,\n    image_size = IMG_SIZE\n)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"посмотрим на первые 9 изображений и меток из обучающего набора"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Необходимо определить, сколько пакетов данных доступно в наборе проверки, используя tf.data.experimental.cardinality , а затем переместим 20% из них в набор тестов."},{"metadata":{"trusted":true},"cell_type":"code","source":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches // 5)\nvalidation_dataset = validation_dataset.skip(val_batches // 5)\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Используем буферизованную предварительную выборку для загрузки изображений с диска без блокировки ввода-вывода"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Искусственно введем разнообразие образцов, применяя случайные, но реалистичные преобразования к обучающим изображениям, такие как поворот и горизонтальный поворот. Это помогает раскрыть модель различным аспектам обучающих данных и уменьшить переобучение ."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation=tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(.5, .2),\n    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"проверим внесенное разнообразие слоев - визуализируем первое изображение, учитывая разные повороты"},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, _ in train_dataset.take(1):\n  plt.figure(figsize=(10, 10))\n  first_image = image[0]\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n    plt.imshow(augmented_image[0] / 255)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Создадим базовую модель из предварительно обученных сверток"},{"metadata":{},"cell_type":"markdown","source":"Для извлечения функций модели возьмем  слой «узкое место» -  элементы слоя  сохраняют большую универсальность по сравнению с последним / верхним слоем."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_shape=IMG_SIZE+(3,)\nbase_model=tf.keras.applications.EfficientNetB3(input_shape=image_shape,\n                                    include_top=False,\n                                    weights='imagenet',\n                                    drop_connect_rate=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Извлечение признаков\n\nНа этом шаге заморозим сверточную базу, созданную на предыдущем шаге, и будем использовать ее в качестве средства извлечения признаков. Плюс добавим поверх него классификатор и обучим классификатор верхнего уровня.\n\nЗаморозить сверточную базу\n\nПеред компиляцией и обучением модели важно заморозить сверточную базу. Замораживание (путем установки layer.trainable = False) предотвращает обновление весов в данном слое во время обучения. EfficientNet имеет много уровней, поэтому установка для trainable флага всей модели значения False заморозит их все."},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавить заголовок классификации\n\nЧтобы сгенерировать прогнозы на основе блока функций, используем слой tf.keras.layers.GlobalAveragePooling2D"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.Sequential()\nmodel.add(base_model)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(tf.keras.layers.Dense(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создадим модель, объединив вместе слои"},{"metadata":{"trusted":true},"cell_type":"code","source":"input=tf.keras.Input(image_shape)\nx=data_augmentation(input)\nx=base_model(x,training=False)\nx=tf.keras.layers.GlobalAveragePooling2D()(x)\nx=tf.keras.layers.Dropout(0.2)(x)\nx=tf.keras.layers.BatchNormalization()(x)\noutput=tf.keras.layers.Dense(1)(x)\nmodel=tf.keras.Model(input,output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Скомпилируем модель\n\nСкомпилируем модель перед ее обучением"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучим модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"init_epochs=10\n\nhistory=model.fit(train_dataset,\n          epochs=init_epochs,\n          validation_data=validation_dataset\n         )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Кривые обучения\n\nДавайте посмотрим на кривые обучения точности / потери обучения и проверки при использовании базовой предобученной модели  в качестве экстрактора фиксированных функций."},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В меньшей степени это также связано с тем, что метрики обучения сообщают среднее значение за эпоху, тогда как метрики валидации оцениваются после эпохи, поэтому метрики валидации видят модель, которая тренировалась немного дольше."},{"metadata":{},"cell_type":"markdown","source":"Тонкая настройка\n\nВ эксперименте по извлечению признаков мы тренировали только несколько слоев поверх базовой модели EfficientNet V2. Веса предварительно обученной сети не обновлялись во время обучения.\n\nОдин из способов еще больше повысить производительность - это обучить (или «точно настроить») веса верхних слоев предварительно обученной модели вместе с обучением добавленного нами классификатора. Процесс обучения заставит настраивать веса с общих карт объектов на объекты, связанные специально с набором данных."},{"metadata":{},"cell_type":"markdown","source":"Разморозить верхние слои модели\n\nВсе, что вам нужно сделать, это разморозить base_model и сделать нижние слои base_model . Затем нам следует перекомпилировать модель (необходимо, чтобы эти изменения вступили в силу) и возобновить обучение."},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of layers in the base model: \", len(base_model.layers))\n\nfine_tune_at = 100\n\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Скомпилируйте модель\n\nПоскольку мы тренируем гораздо большую модель и хотим повторно адаптировать предварительно обученные веса, на этом этапе важно использовать более низкую скорость обучения. В противном случае наша модель может очень быстро переобучиться"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_learning_rate=0.0001\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Продолжить обучение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune_epochs = 10\ntotal_epochs =  init_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Давайте посмотрим на кривые обучения точности / потери обучения и проверки при тонкой настройке последних нескольких уровней базовой предобученной модели  и обучении классификатора поверх нее. Потеря проверки намного выше, чем потеря тренировки, поэтому мы можем получить некоторое переобучение.\n\nМы также можем столкнуться с переобучением, поскольку новый обучающий набор относительно невелик и похож на исходные наборы данных предобученной модели.\n\nПосле точной настройки модель достигает около 99% точности на проверочном наборе."},{"metadata":{"trusted":true},"cell_type":"code","source":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([init_epochs-1,init_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([init_epochs-1,init_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Оценка и прогноз\n\nНаконец, мы можем проверить работоспособность модели на новых данных с помощью набора тестов."},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"И теперь мы готовы использовать эту модель, чтобы предсказать конечную цель - лицо в маске или без"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\n\n# Apply a sigmoid since our model returns logits\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', label_batch)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].astype(\"uint8\"))\n  plt.title(class_names[predictions[i]])\n  plt.axis(\"off\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}